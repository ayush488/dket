"""Metrics for `dket` model evaluation."""

import tensorflow as tf


class Metrics(object):
    """A function used to judge performances of the model."""

    def __init__(self, name, func):
        """Initialize a new instance.

        Arguments:
          name: a `str` with the name for the current metric, to be used for
            the scalar summary.
          func: a function that calculates the actual metrics. The signature
            of this function must be the same of the the `compute` method.
        """
        self._name = name
        self._func = func

    @property
    def name(self):
        """The given name for the metric."""
        return self._name

    def __call__(self, target, output, weights=None):
        """Wrapper for the `compute` method."""
        return self.compute(target, output, weights=weights)

    def compute(self, target, output, weights=None):
        """Compute a set of evaluation metrics on the results.

        Arguments:
          target: the truth label `Tensor`, with `tf.int32` as `dtype`. It has rank
            `[d_0, d_1, ..., d_{r-1}]` and the last value is supposed to range between
            `0` and `num_classes - 1`.
          output: the model output `Tensor` with `tf.float32` as `dtype`. It has shape
            `[d_0, d_1, ..., d_{r-1}, num_classes]` and dtype `float32` and represents the
            probability distribution across the output classes generated by the model.
          weights: coefficients for the loss. This must be scalar or of same rank as `labels`.

        Returns:
          a tensor objects representing the evaluation metrics for the model.
        """
        tensor = self._func(target, output, weights=weights)
        tf.summary.scalar(self._name, tensor)
        return tensor

    @staticmethod
    def mean_categorical_accuracy():
        """Compute the mean categorical accuracy on a batch.

        Returns:
          a `Metrics` instance that returns a tensor representing
          the average accuracy of the predicted output w.r.t. the target.
        """
        def _func(target, output, weights=None):
            return mean_categorical_accuracy(target, output, weights=weights)
        return Metrics('mean_categorical_accuracy', _func)


def mean_categorical_accuracy(target, output, weights=None):
    """Computes the mean categorical accuracy between `truth` and `predictions`.

    Arguments:
      target: the truth label `Tensor`, with `tf.int32` as `dtype`. It has rank
        `[d_0, d_1, ..., d_{r-1}]` and the last value is supposed to range between
        `0` and `num_classes - 1`.
      output: the model output `Tensor` with `tf.float32` as `dtype`. It has shape
        `[d_0, d_1, ..., d_{r-1}, num_classes]` and dtype `float32` and represents the
        probability distribution across the output classes generated by the model.
      weights: coefficients for the loss. This must be scalar or of same rank as `labels`.
      scope: `str` or `tr.VariableScope`, is the scope for the operations
        performed in computing the loss.

    Returns:
      A `Tensor` of `0D` (i.e. a scalar) representing the mean categorical accuracy.
    """
    actual = tf.cast(tf.argmax(output, axis=-1), tf.int32)
    is_equal = tf.cast(tf.equal(target, actual), tf.float32)
    if weights is not None:
        actual = tf.multiply(weights, is_equal)
        weights = tf.multiply(weights, tf.ones_like(is_equal))
        return tf.div(tf.reduce_sum(actual), tf.reduce_sum(weights))
    return tf.reduce_mean(is_equal)
