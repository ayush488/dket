"""Loss functions for `dket` models."""

import functools

import tensorflow as tf

from dket.common import _EPSILON

class Loss(object):
    """Base implementation of a loss function."""

    def __init__(self, func):
        """Initialize the Loss object."""
        self._func = func

    @property
    def func(self):
        """The wrapped function."""
        return self._func

    def compute(self, truth, predicted, weights=1.0):
        """Compute the loss invoking the inner function."""
        return self._func(truth, predicted, weights=weights)

    def __call__(self, truth, predicted, weights=1.0):
        return self.compute(truth, predicted, weights=weights)

    @staticmethod
    def categorical_crossentropy(scope=None, loss_collection=tf.GraphKeys.LOSSES):
        """Loss function implementing a categorical cross entropy."""
        return Loss(func=functools.partial(
            categorical_crossentropy,
            scope=scope, loss_collection=loss_collection))


def categorical_crossentropy(target, output, weights=1.0,
                             scope='CrossEntropy',
                             loss_collection=tf.GraphKeys.LOSSES):
    """Computes the categorical cross entropy between `target` and `predictions`.

    Arguments:
      target: the truth label `Tensor`, with `tf.int32` as `dtype`. It has rank
        `[d_0, d_1, ..., d_{r-1}]` and the last value is supposed to range between
        `0` and `num_classes - 1`.
      output: the model output `Tensor` with `tf.float32` as `dtype`. It has shape
        `[d_0, d_1, ..., d_{r-1}, num_classes]` and dtype `float32` and represents the
        probability distribution across the output classes generated by the model.
      weights: coefficients for the loss. This must be scalar or of same rank as `labels`.
      scope: `str` or `tr.VariableScope`, is the scope for the operations
        performed in computing the loss.
      loss_collection: `str`, key for the collection to which the loss will be added.

    Returns:
      A `Tensor` of `0D` (i.e. a scalar) representing the mean loss value.
    """
    eps = tf.convert_to_tensor(_EPSILON, dtype=tf.float32)
    logits = tf.log(tf.clip_by_value(output, eps, 1 - eps))
    return tf.losses.sparse_softmax_cross_entropy(
        labels=target, logits=logits, weights=weights,
        scope=scope, loss_collection=loss_collection)